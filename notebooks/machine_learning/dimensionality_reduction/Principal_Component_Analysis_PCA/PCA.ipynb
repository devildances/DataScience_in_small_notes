{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit ('datasciencenote')",
   "display_name": "Python 3.8.6 64-bit ('datasciencenote')",
   "metadata": {
    "interpreter": {
     "hash": "d301a79a4c72a9c4597d10e7d49a765ad604cfb809248e0230d5a3f688077c5c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h1 style=\"text-align:center\">Principal Component Analysis (PCA)<br>[<a href=\"https://setosa.io/ev/principal-component-analysis/\">source</a>]</h1>\n",
    "<p style=\"font-size:15px\">PCA is considered to be one of the most used unsupervised algorithms and can be seen as the most popular <strong>dimensionality reduction algorithm</strong>.</p>\n",
    "<p style=\"font-size:15px\">PCA is used for operations such as:<ul style=\"font-size:13px\">\n",
    "        <li>Noise filtering\n",
    "        <li>Visualization\n",
    "        <li>Feature Extraction\n",
    "        <li>Stock market predictions\n",
    "        <li>Gene data analysis\n",
    "        <li>and more\n",
    "    </ul>\n",
    "</p><br>\n",
    "\n",
    "<p style=\"font-size:15px\">The goal of PCA:<ul style=\"font-size:15px\">\n",
    "        <li>Identify patterns in data\n",
    "        <li>Detect correlation between variables<ul>\n",
    "                <li>Detect correlation between variables, if there is a strong correlation and it`s found then we could reduce the dimensionality which really what PCA is intended for\n",
    "                <li>We find the directions of maximum variance in high dimensional data and the project it into a smaller dimensional subspace while retaining most of the information\n",
    "            </ul>\n",
    "        <li>Usually, with PCA the goal to reduce the dimensions of a d-dimensional dataset onto a k-dimensional subspace where <i><strong>k</strong></i> is less than <i><strong>d</strong></i> (<i><strong>k < d</strong></i>) \n",
    "    </ul>\n",
    "</p><br>\n",
    "\n",
    "<p style=\"font-size:15px\">The main functions of the PCA algorithm whould be:<ul style=\"font-size:15px\">\n",
    "        <li>Standardize the data\n",
    "        <li>Obtain the Eigenvectors and Eigenvalues from the covariance matrix or correlation matrix, or perform Singular Vector Decomposition\n",
    "        <li>Sort Eigenvalues in descending order and choose the <i>k</i> Eigenvectors that correspond to the <i>k</i> largest Eigenvalues where <i>k</i> is the number of dimensions of the new feature subspace (<i>k <= d</i>)\n",
    "        <li>Construct the projection matrix <i><strong>W</strong></i> from the selected <i>k</i> Eigenvectors\n",
    "        <li>Transform the original dataset <i><strong>X</strong></i> via <i><strong>W</strong></i> to obtain a k-dimensional feature subspace <i><strong>Y</strong></i>\n",
    "        <li><a href=\"https://plot.py/ipython-notebooks/principal-component-analysis/\">source</a>\n",
    "    </ul>\n",
    "</p><br>\n",
    "\n",
    "<p style=\"font-size:18px\"><strong>PCA does have a weakness, which is highly affected by outliers in the data but it is considered to be one of the most used and extremely popular to use.</strong></p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---\n",
    "<h2>1. Importing the Dataset</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   Alcohol  Malic_Acid   Ash  Ash_Alcanity  Magnesium  Total_Phenols  \\\n0    14.23        1.71  2.43          15.6        127           2.80   \n1    13.20        1.78  2.14          11.2        100           2.65   \n2    13.16        2.36  2.67          18.6        101           2.80   \n3    14.37        1.95  2.50          16.8        113           3.85   \n4    13.24        2.59  2.87          21.0        118           2.80   \n\n   Flavanoids  Nonflavanoid_Phenols  Proanthocyanins  Color_Intensity   Hue  \\\n0        3.06                  0.28             2.29             5.64  1.04   \n1        2.76                  0.26             1.28             4.38  1.05   \n2        3.24                  0.30             2.81             5.68  1.03   \n3        3.49                  0.24             2.18             7.80  0.86   \n4        2.69                  0.39             1.82             4.32  1.04   \n\n   OD280  Proline  Customer_Segment  \n0   3.92     1065                 1  \n1   3.40     1050                 1  \n2   3.17     1185                 1  \n3   3.45     1480                 1  \n4   2.93      735                 1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Alcohol</th>\n      <th>Malic_Acid</th>\n      <th>Ash</th>\n      <th>Ash_Alcanity</th>\n      <th>Magnesium</th>\n      <th>Total_Phenols</th>\n      <th>Flavanoids</th>\n      <th>Nonflavanoid_Phenols</th>\n      <th>Proanthocyanins</th>\n      <th>Color_Intensity</th>\n      <th>Hue</th>\n      <th>OD280</th>\n      <th>Proline</th>\n      <th>Customer_Segment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14.23</td>\n      <td>1.71</td>\n      <td>2.43</td>\n      <td>15.6</td>\n      <td>127</td>\n      <td>2.80</td>\n      <td>3.06</td>\n      <td>0.28</td>\n      <td>2.29</td>\n      <td>5.64</td>\n      <td>1.04</td>\n      <td>3.92</td>\n      <td>1065</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13.20</td>\n      <td>1.78</td>\n      <td>2.14</td>\n      <td>11.2</td>\n      <td>100</td>\n      <td>2.65</td>\n      <td>2.76</td>\n      <td>0.26</td>\n      <td>1.28</td>\n      <td>4.38</td>\n      <td>1.05</td>\n      <td>3.40</td>\n      <td>1050</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13.16</td>\n      <td>2.36</td>\n      <td>2.67</td>\n      <td>18.6</td>\n      <td>101</td>\n      <td>2.80</td>\n      <td>3.24</td>\n      <td>0.30</td>\n      <td>2.81</td>\n      <td>5.68</td>\n      <td>1.03</td>\n      <td>3.17</td>\n      <td>1185</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14.37</td>\n      <td>1.95</td>\n      <td>2.50</td>\n      <td>16.8</td>\n      <td>113</td>\n      <td>3.85</td>\n      <td>3.49</td>\n      <td>0.24</td>\n      <td>2.18</td>\n      <td>7.80</td>\n      <td>0.86</td>\n      <td>3.45</td>\n      <td>1480</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13.24</td>\n      <td>2.59</td>\n      <td>2.87</td>\n      <td>21.0</td>\n      <td>118</td>\n      <td>2.80</td>\n      <td>2.69</td>\n      <td>0.39</td>\n      <td>1.82</td>\n      <td>4.32</td>\n      <td>1.04</td>\n      <td>2.93</td>\n      <td>735</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../../../../data/clean/Wine.csv')\n",
    "display(df.head())\n",
    "x = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "source": [
    "---\n",
    "<h2>2. Splitting the Dataset</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "train dataset size : 142 observations\ntest dataset size : 36 observations\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "print(\"train dataset size : {} observations\\ntest dataset size : {} observations\".format(x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "source": [
    "---\n",
    "<h2>3. Feature Scaling</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stand_x = StandardScaler().fit(x_train)\n",
    "x_ss = stand_x.transform(x_train)"
   ]
  },
  {
   "source": [
    "---\n",
    "<h2>4. Applying PCA and KernelPCA</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "\n",
    "pca = PCA(n_components=2).fit(x_ss)\n",
    "kpca = KernelPCA(n_components=2, kernel='rbf').fit(x_ss)\n",
    "x_pca = pca.transform(x_ss)\n",
    "x_kpca = kpca.transform(x_ss)"
   ]
  },
  {
   "source": [
    "---\n",
    "<h2>5. Training the Logistic Regression Model (for testing purpose) on The Training Dataset</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LogisticRegression(random_state=0)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_pca = LogisticRegression(random_state=0)\n",
    "logreg_kpca = LogisticRegression(random_state=0)\n",
    "logreg_pca.fit(x_pca, y_train)\n",
    "logreg_kpca.fit(x_kpca, y_train)"
   ]
  },
  {
   "source": [
    "---\n",
    "<h2>6. Predicting the Test Dataset Results</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   y actual  y pca  y kernel_pca\n0         1      1             1\n1         3      3             3\n2         2      2             2\n3         1      1             1\n4         2      2             2\n5         2      1             2\n6         1      1             1\n7         3      3             3\n8         2      2             2\n9         2      2             2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>y actual</th>\n      <th>y pca</th>\n      <th>y kernel_pca</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "y_pred_pca = logreg_pca.predict(pca.transform(stand_x.transform(x_test)))\n",
    "y_pred_kpca = logreg_kpca.predict(kpca.transform(stand_x.transform(x_test)))\n",
    "\n",
    "pd.DataFrame(data=np.stack((y_test, y_pred_pca, y_pred_kpca), axis=1),\n",
    "             index=None, columns=['y actual', 'y pca', 'y kernel_pca'],\n",
    "             copy=False).head(10)"
   ]
  },
  {
   "source": [
    "---\n",
    "<h2>7. Making the Confusion Matrix</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[14  0  0]\n [ 1 15  0]\n [ 0  0  6]]\n\nConfusion matrix result for PCA shows that:\n\t- 14 correct predictions of the customer segment 1        \n\t- 15 correct predictions of the customer segment 2        \n\t- 6 correct predictions of the customer segment 3\n\n==================================================\n\n[[14  0  0]\n [ 0 16  0]\n [ 0  0  6]]\n\nConfusion matrix result for KernelPCA shows that:\n\t- 14 correct predictions of the customer segment 1        \n\t- 16 correct predictions of the customer segment 2        \n\t- 6 correct predictions of the customer segment 3\n"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_pca))\n",
    "print(\"\\nConfusion matrix result for PCA shows that:\\n\\t- 14 correct predictions of the customer segment 1\\\n",
    "        \\n\\t- 15 correct predictions of the customer segment 2\\\n",
    "        \\n\\t- 6 correct predictions of the customer segment 3\")\n",
    "print(\"\\n\"+\"=\"*50+\"\\n\")\n",
    "print(confusion_matrix(y_test, y_pred_kpca))\n",
    "print(\"\\nConfusion matrix result for KernelPCA shows that:\\n\\t- 14 correct predictions of the customer segment 1\\\n",
    "        \\n\\t- 16 correct predictions of the customer segment 2\\\n",
    "        \\n\\t- 6 correct predictions of the customer segment 3\")"
   ]
  }
 ]
}